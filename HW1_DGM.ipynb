{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Generative Models\n",
        "## Homework 1\n",
        "###Virginia Marcante - UIN: 664215958"
      ],
      "metadata": {
        "id": "wy54d_mwLHaU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGDm2nEwKxkg"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3DdjKx2JLhZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "from torch import distributions\n",
        "from torch.utils.data import DataLoader \n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms as T\n",
        "from NADE import *\n",
        "from PixelRNN import *\n",
        "from Transformer import *"
      ],
      "metadata": {
        "id": "AJpdUtzqLGbU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose first the model you want to train:"
      ],
      "metadata": {
        "id": "yvxWiaLAO0XR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model = NADE(input_dim=784, hidden_dim=500)"
      ],
      "metadata": {
        "id": "pgcVkcQQO4OG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PixelRNN(num_layers=2, hidden_dims=16, input_size=28)"
      ],
      "metadata": {
        "id": "qEHbJm-KO5GG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Parameters():\n",
        "  channels = 1\n",
        "  image_size = 28\n",
        "  hidden_size = 100\n",
        "  nlayers = 1\n",
        "  num_heads = 2\n",
        "  total_key_depth = 0 # If 0, uses hidden_size instead\n",
        "  total_value_depth = 0\n",
        "  attn_type = \"local_1d\"\n",
        "  filter_size = 2048 # in ffn\n",
        "  dropout = 0.3\n",
        "  block_length = 256\n",
        "\n",
        "model = Transformer(Parameters())"
      ],
      "metadata": {
        "id": "hvyio8dHO5RM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "transforms = T.Compose([T.Lambda(lambda t : np.round((np.array(t) / 27)).astype(int)), T.ToTensor()])\n",
        "\n",
        "training_data = torchvision.datasets.FashionMNIST(\"dataset\", download=True, train=True, transform=transforms)\n",
        "test_data = torchvision.datasets.FashionMNIST(\"dataset\", download=True, train=False, transform=transforms)\n",
        "\n",
        "train_loader = DataLoader(training_data, shuffle=True, batch_size=batch_size, num_workers=8)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=1, num_workers=8)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "n_epochs = 5\n",
        "train_loss = []\n",
        "eval_loss = []\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  epochs_loss = []\n",
        "\n",
        "  for image, _ in train_loader:\n",
        "\n",
        "    l = [1, 2, 3]\n",
        "    #x = torch.Tensor(image)\n",
        "    #optimizer.zero_grad()\n",
        "    #y_pred = model(x.float())\n",
        "    #l = model.loss(x, y_pred)\n",
        "    #epochs_loss.append(l)\n",
        "    #l.backward()\n",
        "    #optimizer.step()\n",
        "\n",
        "  epoch_loss = np.mean(l)\n",
        "  train_loss.append(epoch_loss)\n",
        "  eval_epoch_loss = model.evaluation(test_loader)\n",
        "  eval_loss.append(eval_epoch_loss)\n",
        "\n",
        "  print (f\"Epoch: {epoch}, Training Loss: {epoch_loss:.2f}, Evaluation Loss: {eval_epoch_loss:.2f}\")"
      ],
      "metadata": {
        "id": "u-zz_wD2M-IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(4, 3))\n",
        "ax = plt.axes()\n",
        "ax.plot(eval_loss, 'b-', label = 'Test loss')\n",
        "ax.plot(train_loss, 'r-', label = 'Train loss')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Loss')\n",
        "lgd = ax.legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.2), ncol = 2, fancybox = True)\n",
        "plt.savefig('interpolation.eps', format='eps', bbox_extra_artists = (lgd,), bbox_inches = 'tight') \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E6wWnP_0UaGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_grid(imlist, m, n):\n",
        "  fig, grid = plt.subplots(m,n) \n",
        "  for i in range(m):\n",
        "    for j in range(n):\n",
        "      grid[i,j].axis('off')\n",
        "      grid[i,j].imshow(np.reshape(imlist[(i-1)*m+j], (28,28)))"
      ],
      "metadata": {
        "id": "7uLK74b8VBEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sampling for NADE\n"
      ],
      "metadata": {
        "id": "QphgZwd6TyTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "draw_grid(model.sample(16), 4, 4)"
      ],
      "metadata": {
        "id": "1qjo5jmOTycx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sampling for Pixel RNN and Transformer"
      ],
      "metadata": {
        "id": "LOFUMnCyTt8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_samples = torch.zeros(16, 28, 28)\n",
        "for i in range(16):\n",
        "  for j in range(28):\n",
        "    for k in range(28):\n",
        "      new_samples[i, j, k] = torch.multinomial(model.sample()[i, :, j, k].squeeze(), 1)\n",
        "draw_grid(new_samples, 4, 4)"
      ],
      "metadata": {
        "id": "jVq68XnUTJSJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}